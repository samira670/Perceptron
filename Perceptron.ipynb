{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TdDzzbeqPPs",
        "outputId": "08c45231-75a5-42b3-eddb-2a8a958ffd04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93         7\n",
            "           1       0.89      0.73      0.80        11\n",
            "           2       0.85      0.92      0.88        12\n",
            "\n",
            "    accuracy                           0.87        30\n",
            "   macro avg       0.87      0.88      0.87        30\n",
            "weighted avg       0.87      0.87      0.86        30\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=17)\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "standardize = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform it\n",
        "standardized_x_train = standardize.fit_transform(x_train)\n",
        "\n",
        "# Transform the test data using the same scaler\n",
        "standardized_x_test = standardize.transform(x_test)\n",
        "\n",
        "# Create and train the Perceptron model\n",
        "perceptron = Perceptron(max_iter=50, eta0=0.15, tol=1e-3, random_state=15)\n",
        "perceptron.fit(standardized_x_train, y_train.ravel())\n",
        "\n",
        "# Predict on the standardized test data\n",
        "y_pred = perceptron.predict(standardized_x_test)\n",
        "\n",
        "# Import classification report and confusion matrix to evaluate the model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ]
}